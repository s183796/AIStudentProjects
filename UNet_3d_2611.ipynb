{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s183796/AIStudentProjects/blob/christine/UNet_3d_2611.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8awFvthKz1k",
        "outputId": "84793181-35f1-4901-e5d1-28e99905a29d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image, display, clear_output\n",
        "import numpy as np\n",
        "%matplotlib nbagg\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "from torch.nn.functional import relu\n",
        "from torch.nn.functional import softmax\n",
        "import PIL.Image\n",
        "import os\n",
        "import torchvision\n",
        "import cv2\n",
        "\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms.functional as TF\n",
        "import glob\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_qHheG0jv6oM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "ayULTtZEwito"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmR7LP3jMgsN"
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module): #from https://towardsdatascience.com/cook-your-first-u-net-in-pytorch-b3297a844cf3\n",
        "    def __init__(self, n_class):\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder\n",
        "        # In the encoder, convolutional layers with the Conv2d function are used to extract features from the input image.\n",
        "        # Each block in the encoder consists of two convolutional layers followed by a max-pooling layer, with the exception of the last block which does not include a max-pooling layer.\n",
        "        # -------\n",
        "        # input: 1x128x128\n",
        "        self.e11 = nn.Conv3d(1, 64, kernel_size=3,padding=1)\n",
        "        self.e12 = nn.Conv3d(64, 64, kernel_size=3,padding=1)\n",
        "        self.pool1 = nn.MaxPool3d(kernel_size=2, stride=2) #64x64x64\n",
        "\n",
        "        self.e21 = nn.Conv3d(64, 128, kernel_size=3,padding=1)\n",
        "        self.e22 = nn.Conv3d(128, 128, kernel_size=3,padding=1)\n",
        "        self.pool2 = nn.MaxPool3d(kernel_size=2, stride=2) #32x32x128\n",
        "\n",
        "        self.e31 = nn.Conv3d(128, 256, kernel_size=3,padding=1)\n",
        "        self.e32 = nn.Conv3d(256, 256, kernel_size=3,padding=1)\n",
        "        self.pool3 = nn.MaxPool3d(kernel_size=2, stride=2) #16x16x256\n",
        "\n",
        "        self.e41 = nn.Conv3d(256, 512, kernel_size=3,padding=1)\n",
        "        self.e42 = nn.Conv3d(512, 512, kernel_size=3,padding=1)\n",
        "\n",
        "        '''\n",
        "        self.pool4 = nn.MaxPool3d(kernel_size=2, stride=2) #8x8x512\n",
        "\n",
        "\n",
        "        self.e51 = nn.Conv3d(512, 1024, kernel_size=3,padding=1)\n",
        "        self.e52 = nn.Conv3d(1024, 1024, kernel_size=3,padding=1)\n",
        "\n",
        "        self.upconv1 = nn.ConvTranspose3d(1024,512,kernel_size=2,stride=2) #16x16x1024\n",
        "        self.d11 = nn.Conv3d(1024,512,kernel_size=3,padding=1)\n",
        "        self.d12 = nn.Conv3d(512,512,kernel_size=3,padding=1)\n",
        "        '''\n",
        "        self.upconv2 = nn.ConvTranspose3d(512,256,kernel_size=2,stride=2) #\n",
        "        self.d21 = nn.Conv3d(512,256,kernel_size=3,padding=1)\n",
        "        self.d22 = nn.Conv3d(256,256,kernel_size=3,padding=1)\n",
        "\n",
        "        self.upconv3 = nn.ConvTranspose3d(256,128,kernel_size=2,stride=2)\n",
        "        self.d31 = nn.Conv3d(256,128,kernel_size=3,padding=1)\n",
        "        self.d32 = nn.Conv3d(128,128,kernel_size=3,padding=1)\n",
        "\n",
        "        self.upconv4 = nn.ConvTranspose3d(128,64,kernel_size=2,stride=2)\n",
        "        self.d41 = nn.Conv3d(128,64,kernel_size=3,padding=1)\n",
        "        self.d42 = nn.Conv3d(64,64,kernel_size=3,padding=1)\n",
        "\n",
        "        self.outconv = nn.Conv3d(64, n_class, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        xe11 = F.relu(self.e11(x))\n",
        "        xe12 = F.relu(self.e12(xe11))\n",
        "        xp1 = self.pool1(xe12)\n",
        "\n",
        "        xe21 = F.relu(self.e21(xp1))\n",
        "        xe22 = F.relu(self.e22(xe21))\n",
        "        xp2 = self.pool2(xe22)\n",
        "\n",
        "\n",
        "        xe31 = F.relu(self.e31(xp2))\n",
        "        xe32 = F.relu(self.e32(xe31))\n",
        "\n",
        "        xp3 = self.pool3(xe32)\n",
        "\n",
        "        xe41 = F.relu(self.e41(xp3))\n",
        "        xe42 = F.relu(self.e42(xe41))\n",
        "\n",
        "\n",
        "        #xp4 = self.pool4(xe42)\n",
        "\n",
        "        #xe51 = F.relu(self.e51(xp4))\n",
        "        #xe52 = F.relu(self.e52(xe51))\n",
        "\n",
        "        # Up-convolutions\n",
        "        #xup1 = self.upconv1(xe52)\n",
        "        #xcat=xup1\n",
        "        #xcat = torch.cat([xup1, xe42], dim=1)\n",
        "\n",
        "        #xup21 = F.relu(self.d11(xcat))\n",
        "        #xup22 = F.relu(self.d12(xup21))\n",
        "\n",
        "        xup2 = self.upconv2(xe42)\n",
        "        #xcat2=xup2\n",
        "        #xcat2 = torch.cat([xup2, xe32[:,:,:-1,:-1]], dim=1)\n",
        "        xcat2 = torch.cat([xup2, xe32], dim=1)\n",
        "\n",
        "\n",
        "        xup31 = F.relu(self.d21(xcat2))\n",
        "        xup32 = F.relu(self.d22(xup31))\n",
        "        xup3 = self.upconv3(xup32)\n",
        "        #xcat3=xup3\n",
        "        xcat3 = torch.cat([xup3, xe22], dim=1)\n",
        "\n",
        "        xup41 = F.relu(self.d31(xcat3))\n",
        "        xup42 = F.relu(self.d32(xup41))\n",
        "\n",
        "        xup4 = self.upconv4(xup42)\n",
        "        #xcat4 = torch.cat([xup4, xe12[:,:,2:-3,2:-3]], dim=1)\n",
        "        xcat4 = torch.cat([xup4, xe12], dim=1)\n",
        "        xup51 = F.relu(self.d41(xcat4))\n",
        "        xup52 = F.relu(self.d42(xup51))\n",
        "\n",
        "        out = self.outconv(xup52)\n",
        "\n",
        "        output = softmax(out,dim=1)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qzsg0ha3ESMZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ax5Mtst7Eoeo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RT2I5QamDF2X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smbMc8I45k87"
      },
      "outputs": [],
      "source": [
        "#Setting up hyper parameters, from exercise week 6\n",
        "\n",
        "\n",
        "loss_fn =  nn.CrossEntropyLoss()         # <-- Your code here.\n",
        "\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqCSVV6cE9Un"
      },
      "outputs": [],
      "source": [
        "class SOCDataset(Dataset):\n",
        "    def __init__(self, root_dir):\n",
        "        self.root_dir = root_dir\n",
        "        self.image_folder = os.path.join(root_dir, 'data/')\n",
        "        self.label_folder = os.path.join(root_dir, 'labels/')\n",
        "        self.image_filenames = sorted([f for f in os.listdir(self.image_folder) if f.endswith('.tiff')])\n",
        "        self.label_filenames = sorted([f for f in os.listdir(self.label_folder) if f.endswith('.tif')])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      img_name = os.path.join(self.image_folder, self.image_filenames[idx])\n",
        "\n",
        "      number1=img_name[-8:-5]\n",
        "      label_name=os.path.join(self.label_folder,'slice__'+str(number1)+'.tif')\n",
        "\n",
        "      image = cv2.imread(img_name, cv2.IMREAD_GRAYSCALE)\n",
        "      label = cv2.imread(label_name, cv2.IMREAD_GRAYSCALE)\n",
        "      image=torch.from_numpy(np.array(image))\n",
        "      label=torch.from_numpy(np.array(label))\n",
        "\n",
        "      return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqDLd6aV1MIB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpKsXg_j1Gy1"
      },
      "outputs": [],
      "source": [
        "SOC_dataset = SOCDataset(root_dir='drive/My Drive//AI data/')\n",
        "\n",
        "images=[]\n",
        "labels=[]\n",
        "for i in range(len(SOC_dataset)):\n",
        "  image,label=SOC_dataset[i]\n",
        "\n",
        "  images.append(image)\n",
        "  labels.append(label)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bgWqghQdBlHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_cube(volume,cube_size):\n",
        "\n",
        "  vol_split=volume.unfold(2, cube_size, cube_size).unfold(1, cube_size, cube_size).unfold(0, cube_size, cube_size)\n",
        "\n",
        "  vol_split=vol_split.reshape([vol_split.size(0)**3,cube_size,cube_size,cube_size])\n",
        "  return vol_split\n"
      ],
      "metadata": {
        "id": "p-1qAr__ESL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating volumes\n",
        "im_vol=torch.stack(images)\n",
        "labels_vol=torch.stack(labels)\n",
        "\n",
        "#Creating sub volumes\n",
        "im_vol=split_cube(im_vol,64)\n",
        "label_vol=split_cube(labels_vol,64)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D0Pf82rcEu8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pI5ivb7IVQs",
        "outputId": "2ad17b5b-9320-40ef-ef16-f7c86f7e4877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchio in /usr/local/lib/python3.10/dist-packages (0.19.3)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.10/dist-packages (from torchio) (1.2.14)\n",
            "Requirement already satisfied: SimpleITK!=2.0.*,!=2.1.1.1 in /usr/local/lib/python3.10/dist-packages (from torchio) (2.3.1)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from torchio) (4.7.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from torchio) (4.0.2)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from torchio) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torchio) (1.11.3)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.10/dist-packages (from torchio) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchio) (4.66.1)\n",
            "Requirement already satisfied: typer[all] in /usr/local/lib/python3.10/dist-packages (from torchio) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (2.1.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->torchio) (1.14.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from nibabel->torchio) (23.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel->torchio) (67.7.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]->torchio) (8.1.7)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from typer[all]->torchio) (0.4.6)\n",
            "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]->torchio) (1.5.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]->torchio) (13.7.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]->torchio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]->torchio) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1->torchio) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1->torchio) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]->torchio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchio as tio\n",
        "from re import I\n",
        "elements = []\n",
        "for i in range(im_vol.size(0)):\n",
        "    element = tio.Subject(\n",
        "        image_sub=tio.ScalarImage(tensor=im_vol.unsqueeze(0)[:,i,:,:]),\n",
        "        label_sub=tio.LabelMap(tensor=label_vol.unsqueeze(0)[:,i,:,:]),\n",
        "    )\n",
        "    elements.append(element)\n",
        "dataset = tio.SubjectsDataset(elements)"
      ],
      "metadata": {
        "id": "IlFBp4gsHuE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#From https://torchio.readthedocs.io/transforms/transforms.html\n",
        "transforms = (\n",
        "    tio.CropOrPad((32, 32, 32)),\n",
        "    tio.RandomFlip(axes=['LR', 'AP', 'IS']),\n",
        "    tio.ZNormalization(masking_method=tio.ZNormalization.mean)\n",
        ")\n",
        "\n",
        "transform = tio.Compose(transforms)"
      ],
      "metadata": {
        "id": "FYrINGqzKuuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HEKJRtDj2Omv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting in training and test data\n",
        "\n",
        "split=0.7\n",
        "num_subjects = len(dataset)\n",
        "\n",
        "num_training_subjects = int(split * len(dataset))\n",
        "num_validation_subjects = len(dataset) - num_training_subjects\n",
        "num_test_subjects = num_validation_subjects*0.5\n",
        "\n",
        "num_split_subjects = num_training_subjects, num_validation_subjects\n",
        "training_subjects, validation_subjects = torch.utils.data.random_split(elements, num_split_subjects)\n",
        "\n",
        "num_split_subjects_val = int(num_validation_subjects*0.5), int(num_validation_subjects*0.5)+1\n",
        "validation_subjects,test_subjects = torch.utils.data.random_split(validation_subjects,num_split_subjects_val)\n",
        "\n",
        "training_set = tio.SubjectsDataset(\n",
        "    training_subjects, transform=transform)\n",
        "\n",
        "validation_set = tio.SubjectsDataset(\n",
        "    validation_subjects, transform=transform)\n",
        "\n",
        "test_set = tio.SubjectsDataset(\n",
        "    test_subjects, transform=transform)\n",
        "\n",
        "print('Training set:', len(training_set), 'subjects')\n",
        "print('Validation set:', len(validation_set), 'subjects')\n",
        "print('Test set:', len(test_set), 'subjects')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRJ1KZV4L5ZX",
        "outputId": "f7555499-6103-41d1-e19d-3d5049804786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: 240 subjects\n",
            "Validation set: 51 subjects\n",
            "Test set: 52 subjects\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CAs-_4195tq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "num_workers = multiprocessing.cpu_count()\n",
        "\n",
        "training_batch_size = 16\n",
        "validation_batch_size = 2 * training_batch_size\n",
        "\n",
        "training_loader = torch.utils.data.DataLoader(\n",
        "    training_set,\n",
        "    batch_size=training_batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_set,\n",
        "    batch_size=validation_batch_size,\n",
        "    num_workers=num_workers,\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    validation_set,\n",
        "    batch_size=validation_batch_size,\n",
        "    num_workers=num_workers,\n",
        ")"
      ],
      "metadata": {
        "id": "CLxPvlpvMgg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchmetrics"
      ],
      "metadata": {
        "id": "k2n4gIa2pNim",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5f66c95-a1e5-4013-feca-0b0aacecc07c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu118)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.10.0)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlW8ER1KGNL8"
      },
      "outputs": [],
      "source": [
        "from torchmetrics.classification import JaccardIndex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97zj0_jLGX1n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gx_50U0KGbSB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBjIRQ-eBTNO",
        "outputId": "d1bb2e1a-56bf-48bd-cdf4-96e4b8b1fd72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 15      training accuracy with jaccard: 0.19825580716133118\n",
            "             training accuracy with dice: 0.38902562856674194\n",
            "             training accuracy with pixel by pixel: 0.42077207565307617\n",
            "             test accuracy with jaccard: 0.3457412123680115\n",
            "             test accuracy with dice: 0.5184856653213501\n",
            "             test accuracy with pixel by pixel: 0.5939249992370605\n",
            "Step 30      training accuracy with jaccard: 0.418030321598053\n",
            "             training accuracy with dice: 0.5989667177200317\n",
            "             training accuracy with pixel by pixel: 0.6493437886238098\n",
            "             test accuracy with jaccard: 0.45313969254493713\n",
            "             test accuracy with dice: 0.6147007942199707\n",
            "             test accuracy with pixel by pixel: 0.6705383062362671\n",
            "Step 45      training accuracy with jaccard: 0.48582661151885986\n",
            "             training accuracy with dice: 0.6469659209251404\n",
            "             training accuracy with pixel by pixel: 0.6900269389152527\n",
            "             test accuracy with jaccard: 0.4766351282596588\n",
            "             test accuracy with dice: 0.6320415735244751\n",
            "             test accuracy with pixel by pixel: 0.6664266586303711\n",
            "Step 60      training accuracy with jaccard: 0.5318475961685181\n",
            "             training accuracy with dice: 0.6858583092689514\n",
            "             training accuracy with pixel by pixel: 0.7012355923652649\n",
            "             test accuracy with jaccard: 0.4686944782733917\n",
            "             test accuracy with dice: 0.6285260915756226\n",
            "             test accuracy with pixel by pixel: 0.6542383432388306\n",
            "Step 75      training accuracy with jaccard: 0.5251769423484802\n",
            "             training accuracy with dice: 0.6793199181556702\n",
            "             training accuracy with pixel by pixel: 0.7049529552459717\n",
            "             test accuracy with jaccard: 0.5654045939445496\n",
            "             test accuracy with dice: 0.7107648849487305\n",
            "             test accuracy with pixel by pixel: 0.735242486000061\n",
            "Step 90      training accuracy with jaccard: 0.5567442178726196\n",
            "             training accuracy with dice: 0.7072805762290955\n",
            "             training accuracy with pixel by pixel: 0.7204833626747131\n",
            "             test accuracy with jaccard: 0.5653082132339478\n",
            "             test accuracy with dice: 0.7109538316726685\n",
            "             test accuracy with pixel by pixel: 0.7388029098510742\n",
            "Step 105     training accuracy with jaccard: 0.5617523193359375\n",
            "             training accuracy with dice: 0.7132723331451416\n",
            "             training accuracy with pixel by pixel: 0.7321422100067139\n",
            "             test accuracy with jaccard: 0.5233041644096375\n",
            "             test accuracy with dice: 0.6776248812675476\n",
            "             test accuracy with pixel by pixel: 0.7191208600997925\n",
            "Step 120     training accuracy with jaccard: 0.5643385052680969\n",
            "             training accuracy with dice: 0.7144544124603271\n",
            "             training accuracy with pixel by pixel: 0.7303096652030945\n",
            "             test accuracy with jaccard: 0.5749024152755737\n",
            "             test accuracy with dice: 0.7174703478813171\n",
            "             test accuracy with pixel by pixel: 0.7437859177589417\n",
            "Step 135     training accuracy with jaccard: 0.5523900985717773\n",
            "             training accuracy with dice: 0.706563413143158\n",
            "             training accuracy with pixel by pixel: 0.7343705296516418\n",
            "             test accuracy with jaccard: 0.5396177172660828\n",
            "             test accuracy with dice: 0.6886348724365234\n",
            "             test accuracy with pixel by pixel: 0.7157948613166809\n",
            "Step 150     training accuracy with jaccard: 0.534075915813446\n",
            "             training accuracy with dice: 0.6976075768470764\n",
            "             training accuracy with pixel by pixel: 0.7041860222816467\n",
            "             test accuracy with jaccard: 0.598808765411377\n",
            "             test accuracy with dice: 0.740478515625\n",
            "             test accuracy with pixel by pixel: 0.771185040473938\n",
            "Step 165     training accuracy with jaccard: 0.5174795389175415\n",
            "             training accuracy with dice: 0.6843041777610779\n",
            "             training accuracy with pixel by pixel: 0.714963972568512\n",
            "             test accuracy with jaccard: 0.5526496767997742\n",
            "             test accuracy with dice: 0.7040214538574219\n",
            "             test accuracy with pixel by pixel: 0.6967744827270508\n",
            "Step 180     training accuracy with jaccard: 0.5550916790962219\n",
            "             training accuracy with dice: 0.7033759951591492\n",
            "             training accuracy with pixel by pixel: 0.7184785008430481\n",
            "             test accuracy with jaccard: 0.5796298980712891\n",
            "             test accuracy with dice: 0.722955584526062\n",
            "             test accuracy with pixel by pixel: 0.7227514386177063\n",
            "Step 195     training accuracy with jaccard: 0.5822330117225647\n",
            "             training accuracy with dice: 0.7263562679290771\n",
            "             training accuracy with pixel by pixel: 0.7443045377731323\n",
            "             test accuracy with jaccard: 0.5873264074325562\n",
            "             test accuracy with dice: 0.7281993627548218\n",
            "             test accuracy with pixel by pixel: 0.757127046585083\n",
            "Step 210     training accuracy with jaccard: 0.5827825665473938\n",
            "             training accuracy with dice: 0.7314398288726807\n",
            "             training accuracy with pixel by pixel: 0.748874306678772\n",
            "             test accuracy with jaccard: 0.5507689118385315\n",
            "             test accuracy with dice: 0.7018300890922546\n",
            "             test accuracy with pixel by pixel: 0.7444663047790527\n",
            "Step 225     training accuracy with jaccard: 0.5669275522232056\n",
            "             training accuracy with dice: 0.7200711369514465\n",
            "             training accuracy with pixel by pixel: 0.7389904260635376\n",
            "             test accuracy with jaccard: 0.5876635313034058\n",
            "             test accuracy with dice: 0.731201171875\n",
            "             test accuracy with pixel by pixel: 0.7294495701789856\n",
            "Step 240     training accuracy with jaccard: 0.5726648569107056\n",
            "             training accuracy with dice: 0.7216841578483582\n",
            "             training accuracy with pixel by pixel: 0.7463670372962952\n",
            "             test accuracy with jaccard: 0.5156553983688354\n",
            "             test accuracy with dice: 0.6689632534980774\n",
            "             test accuracy with pixel by pixel: 0.7100125551223755\n",
            "Step 255     training accuracy with jaccard: 0.5645182132720947\n",
            "             training accuracy with dice: 0.7156245112419128\n",
            "             training accuracy with pixel by pixel: 0.7413107752799988\n",
            "             test accuracy with jaccard: 0.6539416313171387\n",
            "             test accuracy with dice: 0.7821552157402039\n",
            "             test accuracy with pixel by pixel: 0.8035467863082886\n",
            "Step 270     training accuracy with jaccard: 0.6179561018943787\n",
            "             training accuracy with dice: 0.7535879611968994\n",
            "             training accuracy with pixel by pixel: 0.7716423273086548\n",
            "             test accuracy with jaccard: 0.5783371925354004\n",
            "             test accuracy with dice: 0.7240096926689148\n",
            "             test accuracy with pixel by pixel: 0.7636882066726685\n",
            "Step 285     training accuracy with jaccard: 0.5911887884140015\n",
            "             training accuracy with dice: 0.7416056394577026\n",
            "             training accuracy with pixel by pixel: 0.7614225149154663\n",
            "             test accuracy with jaccard: 0.6551744937896729\n",
            "             test accuracy with dice: 0.7839619517326355\n",
            "             test accuracy with pixel by pixel: 0.8050833940505981\n",
            "Step 300     training accuracy with jaccard: 0.6078335046768188\n",
            "             training accuracy with dice: 0.7481330633163452\n",
            "             training accuracy with pixel by pixel: 0.7618933320045471\n",
            "             test accuracy with jaccard: 0.5767643451690674\n",
            "             test accuracy with dice: 0.7217320203781128\n",
            "             test accuracy with pixel by pixel: 0.7579747438430786\n",
            "Finished training.\n"
          ]
        }
      ],
      "source": [
        "net=UNet(n_class=3)\n",
        "\n",
        "from torchmetrics.functional.classification import dice\n",
        "from torchmetrics.classification import MulticlassAccuracy\n",
        "#metric=Dice(num_classes=3)\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "net.to(device)\n",
        "\n",
        "jaccard=JaccardIndex(task=\"multiclass\", num_classes=3).to(device)\n",
        "accuracy=MulticlassAccuracy(num_classes=3).to(device)\n",
        "batch_size = 16\n",
        "num_epochs = 20 #changing the num_epochs from 2 to 12\n",
        "validation_every_steps = np.ceil(len(training_loader.dataset)/batch_size)\n",
        "\n",
        "step = 0\n",
        "net.train()\n",
        "\n",
        "train_accuracies_jaccard = []\n",
        "train_accuracies_dice = []\n",
        "train_accuracies_pixel = []\n",
        "valid_accuracies_jaccard = []\n",
        "valid_accuracies_dice = []\n",
        "valid_accuracies_pixel = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_accuracies_batches_jaccard = []\n",
        "    train_accuracies_batches_dice = []\n",
        "    train_accuracies_batches_pixel = []\n",
        "\n",
        "    for subjects_batch in training_loader:\n",
        "        inputs = subjects_batch['image_sub'][tio.DATA].to(device)\n",
        "        targets = subjects_batch['label_sub'][tio.DATA].to(device)\n",
        "\n",
        "        # Forward pass, compute gradients, perform one training step.\n",
        "        # Your code here!\n",
        "        # Forward pass.\n",
        "        output = net(inputs)\n",
        "\n",
        "        un_target=targets.unique()\n",
        "        # Compute loss.\n",
        "        targets[targets==un_target[0]]=0\n",
        "        targets[targets==un_target[1]]=1\n",
        "        targets[targets==un_target[2]]=2\n",
        "\n",
        "        targets = targets.to(torch.int64) [:,0,:,:,:]\n",
        "\n",
        "        loss = loss_fn(output, targets)\n",
        "\n",
        "        # Clean up gradients from the model.\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Compute gradients based on the loss from the current batch (backpropagation).\n",
        "        loss.backward()\n",
        "\n",
        "        # Take one optimizer step using the gradients computed in the previous step.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Increment step counter\n",
        "        step += 1\n",
        "\n",
        "        # Compute accuracy.\n",
        "        predictions = torch.argmax(output,dim=1)\n",
        "        train_accuracies_batches_dice.append(dice(predictions,targets).cpu())\n",
        "        train_accuracies_batches_jaccard.append(jaccard(predictions,targets).cpu())\n",
        "        train_accuracies_batches_pixel.append(accuracy(predictions,targets).cpu())\n",
        "\n",
        "        if step % validation_every_steps == 0:\n",
        "\n",
        "            # Append average training accuracy to list.\n",
        "            train_accuracies_jaccard.append(np.mean(train_accuracies_batches_jaccard))\n",
        "            train_accuracies_dice.append(np.mean(train_accuracies_batches_dice))\n",
        "            train_accuracies_pixel.append(np.mean(train_accuracies_batches_pixel))\n",
        "\n",
        "            train_accuracies_batches_jaccard = []\n",
        "            train_accuracies_batches_dice = []\n",
        "            train_accuracies_batches_pixel = []\n",
        "\n",
        "            # Compute accuracies on validation set.\n",
        "            valid_accuracies_batches_jaccard = []\n",
        "            valid_accuracies_batches_dice = []\n",
        "            valid_accuracies_batches_pixel = []\n",
        "            with torch.no_grad():\n",
        "                net.eval()\n",
        "                for subjects_batch in test_loader:\n",
        "                    inputs = subjects_batch['image_sub'][tio.DATA].to(device)\n",
        "                    targets = subjects_batch['label_sub'][tio.DATA].to(device)\n",
        "                    output = net(inputs)\n",
        "\n",
        "                    un_target=targets.unique()\n",
        "                    # Compute loss.\n",
        "                    targets[targets==un_target[0]]=0\n",
        "                    targets[targets==un_target[1]]=1\n",
        "                    targets[targets==un_target[2]]=2\n",
        "\n",
        "                    targets = targets.to(torch.int64) [:,0,:,:,:]\n",
        "\n",
        "                    loss = loss_fn(output, targets)\n",
        "\n",
        "                    predictions = output.max(1)[1]\n",
        "                    # Multiply by len(x) because the final batch of DataLoader may be smaller (drop_last=False).\n",
        "                    valid_accuracies_batches_dice.append(dice(predictions,targets).cpu())\n",
        "                    valid_accuracies_batches_jaccard.append(jaccard(predictions,targets).cpu())\n",
        "                    valid_accuracies_batches_pixel.append(accuracy(predictions,targets).cpu())\n",
        "\n",
        "                net.train()\n",
        "\n",
        "            # Append average validation accuracy to list.\n",
        "            valid_accuracies_jaccard.append(np.sum(valid_accuracies_batches_jaccard) / len(test_loader))\n",
        "            valid_accuracies_dice.append(np.sum(valid_accuracies_batches_dice) / len(test_loader))\n",
        "            valid_accuracies_pixel.append(np.sum(valid_accuracies_batches_pixel) / len(test_loader))\n",
        "\n",
        "            print(f\"Step {step:<5}   training accuracy with jaccard: {train_accuracies_jaccard[-1]}\")\n",
        "            print(f\"             training accuracy with dice: {train_accuracies_dice[-1]}\")\n",
        "            print(f\"             training accuracy with pixel by pixel: {train_accuracies_pixel[-1]}\")\n",
        "            print(f\"             test accuracy with jaccard: {valid_accuracies_jaccard[-1]}\")\n",
        "            print(f\"             test accuracy with dice: {valid_accuracies_dice[-1]}\")\n",
        "            print(f\"             test accuracy with pixel by pixel: {valid_accuracies_pixel[-1]}\")\n",
        "\n",
        "\n",
        "print(\"Finished training.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vP3jaiMblzqL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2uGNOJLejdVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,axs=plt.subplots(1,2,figsize=(15,5))\n",
        "axs[0].plot(train_accuracies_dice,color='red',label='dice')\n",
        "axs[0].plot(train_accuracies_jaccard,color='blue',label='jaccard')\n",
        "axs[0].plot(train_accuracies_pixel,color='green',label='pixel-wise')\n",
        "axs[0].legend()\n",
        "axs[0].set_title('Training accuracies')\n",
        "axs[0].set_xlabel('Epoch number')\n",
        "axs[0].set_ylabel('Accuracy)')\n",
        "\n",
        "axs[1].plot(valid_accuracies_dice,color='red',label='dice')\n",
        "axs[1].plot(valid_accuracies_jaccard,color='blue',label='jaccard')\n",
        "axs[1].plot(valid_accuracies_pixel,color='green',label='pixel-wise')\n",
        "axs[1].legend()\n",
        "axs[1].set_title('Validation accuracies')\n",
        "axs[1].set_xlabel('Epoch number')\n",
        "axs[1].set_ylabel('Accuracy)')\n",
        "\n",
        "fig,axs=plt.subplots(1,3,figsize=(15,5))\n",
        "axs[0].plot(train_accuracies_dice,color='red',label='Training accuracy')\n",
        "axs[0].plot(valid_accuracies_dice,color='blue',label='Validation accuracy')\n",
        "axs[0].set_title('Dice coefficient accuracies')\n",
        "axs[0].legend()\n",
        "\n",
        "axs[1].plot(train_accuracies_jaccard,color='red',label='Training accuracy')\n",
        "axs[1].plot(valid_accuracies_jaccard,color='blue',label='Validation accuracy')\n",
        "axs[1].set_title('Jaccard coefficient accuracies')\n",
        "axs[1].legend()\n",
        "\n",
        "axs[2].plot(train_accuracies_pixel,color='red',label='Training accuracy')\n",
        "axs[2].plot(valid_accuracies_pixel,color='blue',label='Validation accuracy')\n",
        "axs[2].set_title('Pixelwise coefficient accuracies')\n",
        "axs[2].legend()"
      ],
      "metadata": {
        "id": "FmfpaxCY3mdN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "fece4bcb-dc99-4f85-bab8-c17b6e28d313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-22df85a17423>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_accuracies_dice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dice'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_accuracies_jaccard\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'jaccard'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_accuracies_pixel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'green'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pixel-wise'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TY0r8tPEQvAU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.utils import make_grid\n",
        "\n",
        "val_acc_dice=[]\n",
        "val_acc_jaccard=[]\n",
        "val_acc_pixel=[]\n",
        "\n",
        "for subjects_batch in val_loader:\n",
        "  inputs = subjects_batch['image_sub'][tio.DATA].to(device)\n",
        "  targets = subjects_batch['label_sub'][tio.DATA].to(device)\n",
        "  output = net(inputs)\n",
        "\n",
        "  un_target=targets.unique()\n",
        "  # Compute loss.\n",
        "  targets[targets==un_target[0]]=0\n",
        "  targets[targets==un_target[1]]=1\n",
        "  targets[targets==un_target[2]]=2\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6g9ae_A8hleE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label1=output[0,0,:,:,:].cpu().detach().numpy()\n",
        "label2=output[0,1,:,:,:].cpu().detach().numpy()\n",
        "label3=output[0,2,:,:,:].cpu().detach().numpy()\n",
        "\n",
        "x, y, z = np.meshgrid(np.arange(label1.shape[0]),np.arange(label1.shape[1]),np.arange(label1.shape[2]), indexing='ij')\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "# Plot 3D surface\n",
        "im1=ax.scatter(x, y, z, c=label1.flatten(), cmap='viridis', marker='o')\n",
        "plt.title('Label 1, probability')\n",
        "ax.set_xlabel('Dim 1 of volume')\n",
        "ax.set_ylabel('Dim 2 of volume')\n",
        "ax.set_zlabel('Dim 3 of volume')\n",
        "fig.colorbar(im1,label='Probability',ticks=np.linspace(0, 1, 11))\n",
        "plt.title('Label 1, probability')\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "# Plot 3D surface\n",
        "im2=ax.scatter(x, y, z, c=label2.flatten(), cmap='viridis', marker='o')\n",
        "plt.title('Label 2, probability')\n",
        "ax.set_xlabel('Dim 1 of volume')\n",
        "ax.set_ylabel('Dim 2 of volume')\n",
        "ax.set_zlabel('Dim 3 of volume')\n",
        "fig.colorbar(im2,label='Probability',ticks=np.linspace(0, 1, 11))\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "# Plot 3D surface\n",
        "im3=ax.scatter(x, y, z, c=label3.flatten(), cmap='viridis', marker='o')\n",
        "ax.set_xlabel('Dim 1 of volume')\n",
        "ax.set_ylabel('Dim 2 of volume')\n",
        "ax.set_zlabel('Dim 3 of volume')\n",
        "fig.colorbar(im3,label='Probability',ticks=np.linspace(0, 1, 11))\n",
        "# Show the plot\n",
        "plt.title('Label 3, probability')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0uYh12UCOxs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, predicted=output.max(dim=1)\n",
        "\n",
        "predicted=predicted.cpu().detach().numpy() [0,:,:,:]\n",
        "\n",
        "x, y, z = np.meshgrid(np.arange(label1.shape[0]),np.arange(label1.shape[1]),np.arange(label1.shape[2]), indexing='ij')\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "im=ax.scatter(x, y, z, c=predicted.flatten(), cmap='viridis', marker='o')\n",
        "ax.set_xlabel('Dim 1 of volume')\n",
        "ax.set_ylabel('Dim 2 of volume')\n",
        "ax.set_zlabel('Dim 3 of volume')\n",
        "fig.colorbar(im,ticks=[0,1,2],label='Label number')\n",
        "plt.title('Prediction')\n",
        "plt.show()\n",
        "\n",
        "targets=targets.cpu().detach().numpy() [0,:,:,:]\n",
        "x, y, z = np.meshgrid(np.arange(label1.shape[0]),np.arange(label1.shape[1]),np.arange(label1.shape[2]), indexing='ij')\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "im2=ax.scatter(x, y, z, c=targets.flatten(), cmap='viridis', marker='o')\n",
        "ax.set_xlabel('Dim 1 of volume')\n",
        "ax.set_ylabel('Dim 2 of volume')\n",
        "ax.set_zlabel('Dim 3 of volume')\n",
        "fig.colorbar(im2,ticks=[0,1,2],label='Label number')\n",
        "plt.title('Target')\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "im3=ax.scatter(x, y, z, c=np.abs(targets.flatten()-predicted.flatten()), cmap='viridis', marker='o')\n",
        "ax.set_xlabel('Dim 1 of volume')\n",
        "ax.set_ylabel('Dim 2 of volume')\n",
        "ax.set_zlabel('Dim 3 of volume')\n",
        "fig.colorbar(im3,ticks=[0,1,2],label='Difference in label number')\n",
        "plt.title('Absolute difference in labels')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "s35LRbcE33N3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5S23duPOtqvm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oIDqfAO1kl2"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8AXGLJe5GfJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UKsO0WmOYEi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6YVamuFOTtS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}